{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import*\n",
    "import implementations\n",
    "import test_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of Boson events in this set is:  0.342668\n"
     ]
    }
   ],
   "source": [
    "ids, data, pred = load_data(\"train.csv\")\n",
    "perc = np.count_nonzero(pred)/len(pred)\n",
    "print(\"The percentage of Boson events in this set is: \", perc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[138.47        51.655       97.827      ...  67.435        2.15\n",
      "    0.444     ]\n",
      " [160.937       68.768      103.235      ...  46.226        0.725\n",
      "    1.158     ]\n",
      " [121.85852836 162.172      125.953      ...  44.251        2.053\n",
      "   -2.028     ]\n",
      " ...\n",
      " [105.457       60.526       75.839      ...  41.992        1.8\n",
      "   -0.166     ]\n",
      " [ 94.951       19.362       68.812      ...  44.29317834  42.96671343\n",
      "   41.71711609]\n",
      " [121.85852836  72.756       70.831      ...  44.29317834  42.96671343\n",
      "   41.71711609]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Here we try to clean the data \"\"\"\n",
    "# we could do something like: if a column is made of more then 90% of -999, we eliminate that column, and hence condense the array \"data\". The same\n",
    "# could be done with rows (data points). Then, we can run other few lines of code to substitute the remaining -999 with the mean value for that feature\n",
    "# in this way we should obtain usable data\n",
    "\n",
    "\n",
    "# initially, we have 29 columns\n",
    "num = 0.7        # this is the parameter throgh which we decide to eliminate a column or not. with 0.7 we lose 7 columns\n",
    "length = data.shape[1]  \n",
    "i = 0\n",
    "while True:\n",
    "    count = data[:,i][data[:,i]==-999].shape[0] \n",
    "    tot = num*len(data[:,i])        \n",
    "    if count >= tot:\n",
    "        data = np.delete(data, i, 1)      # the 1 stands for column\n",
    "    else:\n",
    "        i = i+1\n",
    "    \n",
    "    if i >=  data.shape[1]:\n",
    "        break\n",
    "\n",
    "        \n",
    "# Now we will try to substitute the remaining -999 values with the average value in that column    \n",
    "count = 0;\n",
    "Sum = 0;\n",
    "for i in range (0, data.shape[1]):\n",
    "    for j in range(0, data.shape[0]):\n",
    "        if (data[j][i] == -999):\n",
    "            continue\n",
    "        else:\n",
    "            Sum += data[j][i]\n",
    "            count += 1\n",
    "            \n",
    "    average = Sum / count\n",
    "    for j in range(0, data.shape[0]):\n",
    "        if (data[j][i] == -999):\n",
    "            data[j][i] = average\n",
    "        \n",
    "\n",
    "# USEFUL PRINTS:\n",
    "# print(data.shape[0])\n",
    "# print(data.shape[1])\n",
    "# print(pred)\n",
    "# data.shape[0]\n",
    "\n",
    "# Let's quickly check whether there are any -999 left in the data matrix\n",
    "count = 0\n",
    "for i in range (0, data.shape[1]):\n",
    "    for j in range (0, data.shape[0]):\n",
    "        if (data[j][i] == -999):\n",
    "            count += 1\n",
    "            \n",
    "print(count)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 3.1 Least squares with gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Least squares with stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Least squares with normal equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Ridge regression with normal equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Logistic regression with gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Regularized logistic regression with gradient descent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
